{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Utils\n",
        "## Import libraries"
      ],
      "metadata": {
        "id": "hRRSbOAqXcK3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2a_cB-GFeNnz"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as tfk\n",
        "from tensorflow.keras import utils, layers, losses, optimizers, models, Sequential, Model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "g9Qeg1lmeXjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_batch_predictions(pred):\n",
        "    '''\n",
        "        Description: is a utility function to decode the output of the inference network\n",
        "        *Args:\n",
        "        pred: output of inference network(prediction)\n",
        "\n",
        "        *Returns:\n",
        "        output_text: List of text: Iterate over the results(of ctc_decode) and get back the text and append them\n",
        "\n",
        "    '''\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    results = tfk.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][:, :max_length]\n",
        "    '''\n",
        "        (tfk.backend.ctc_decode)\n",
        "        *Args:\n",
        "        y_pred: tensor (samples, time_steps, num_categories) containing the prediction, or output of the softmax.\n",
        "        input_length: tensor (samples, ) containing the sequence length for each batch item in y_pred.\n",
        "        greedy: perform much faster best-path search if true. This does not use a dictionary.\n",
        "        beam_width: if greedy is false: a beam search decoder will be used with a beam of this width.\n",
        "        top_paths: if greedy is false, how many of the most probable paths will be returned.\n",
        "\n",
        "\n",
        "        *Returns:\n",
        "        Tuple: List: if greedy is true(like here), returns a list of one element that contains the decoded sequence.\n",
        "        Important: blank labels are returned as -1.\n",
        "        Tensor (top_paths, ) that contains the log probability of each decoded sequence.\n",
        "    '''\n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for res in results:\n",
        "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(res)\n",
        "    return output_text"
      ],
      "metadata": {
        "id": "NNv_oKqseOgA"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}